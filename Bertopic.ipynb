{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970fadbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbertopic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mumap\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "# bertopic_run.py\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import umap\n",
    "\n",
    "DATA = Path(\"data\"); REPORTS = Path(\"reports\"); REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5276115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load texts + (optional) precomputed embeddings ---\n",
    "df = pd.read_parquet(DATA / \"shows_with_cluster_labels.parquet\")\n",
    "df = df[df[\"ai_summary\"].notna() & (df[\"ai_summary\"].str.strip() != \"\")].reset_index(drop=True)\n",
    "texts = df[\"ai_summary\"].tolist()\n",
    "\n",
    "# If you already have SentenceTransformer embeddings (same order as vectors/summaries_index.parquet):\n",
    "X = np.load(\"vectors/summaries.npy\")\n",
    "idx = pd.read_parquet(\"vectors/summaries_index.parquet\")\n",
    "# align to df by id\n",
    "align = pd.merge(idx, df[[\"id\"]], on=\"id\", how=\"inner\").reset_index(drop=True)\n",
    "mask = align.index.values  # rows to select from X in correct order\n",
    "embeddings = X[mask]       # (n, d)\n",
    "\n",
    "print(f\"Texts: {len(texts)} | Embeddings: {embeddings.shape}\")\n",
    "\n",
    "# --- Configure UMAP & Vectorizer ---\n",
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=15, min_dist=0.0, n_components=5, metric=\"cosine\", random_state=42\n",
    ")\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=\"english\", ngram_range=(1, 2), min_df=2, max_df=0.8\n",
    ")\n",
    "\n",
    "# --- Build & fit BERTopic ---\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,                    # dimensionality reduction\n",
    "    vectorizer_model=vectorizer_model,        # c-TF-IDF representation\n",
    "    min_topic_size=10,                        # tweak based on dataset size\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True,\n",
    "    nr_topics=None,                           # or set an int to force a target #topics\n",
    "    seed_topic_list=None\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(texts, embeddings=embeddings)\n",
    "df[\"bertopic_topic\"] = topics\n",
    "print(\"Unique topics (incl. -1):\", sorted(pd.unique(topics)))\n",
    "\n",
    "# --- Topic info (top terms per topic) ---\n",
    "topic_info = topic_model.get_topic_info()  # columns: Topic, Count, Name, Representation\n",
    "topic_terms = []\n",
    "for t in topic_info[\"Topic\"]:\n",
    "    if t == -1:  # outliers\n",
    "        continue\n",
    "    terms = topic_model.get_topic(t)  # list of (term, ctfidf)\n",
    "    topic_terms.append({\n",
    "        \"Topic\": t,\n",
    "        \"TopTerms\": \", \".join([w for w, _ in terms[:10]]),\n",
    "        \"Count\": int(topic_info.loc[topic_info[\"Topic\"]==t, \"Count\"].values[0]),\n",
    "        \"Name\": topic_info.loc[topic_info[\"Topic\"]==t, \"Name\"].values[0]\n",
    "    })\n",
    "topic_terms_df = pd.DataFrame(topic_terms).sort_values(\"Count\", ascending=False)\n",
    "\n",
    "# --- Save per-show topics + per-topic terms ---\n",
    "out_shows = DATA / \"shows_with_bertopic.parquet\"\n",
    "out_topics = DATA / \"bertopic_topics.csv\"\n",
    "df.to_parquet(out_shows, index=False)\n",
    "topic_terms_df.to_csv(out_topics, index=False, encoding=\"utf-8\")\n",
    "print(\"Saved:\", out_shows.resolve())\n",
    "print(\"Saved:\", out_topics.resolve())\n",
    "\n",
    "# --- (Optional) quick text preview per topic\n",
    "for t in topic_terms_df[\"Topic\"].head(5):\n",
    "    examples = df[df[\"bertopic_topic\"]==t][\"ai_summary\"].head(2).tolist()\n",
    "    print(f\"\\nTopic {t} — {topic_model.get_topic_info().set_index('Topic').loc[t,'Name']}\")\n",
    "    print(\"Top terms:\", topic_terms_df[topic_terms_df[\"Topic\"]==t][\"TopTerms\"].values[0])\n",
    "    for e in examples:\n",
    "        print(\"-\", (e[:160] + \"…\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
